{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "#import time libraries\n",
    "import copy\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "#import rest libraries\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "#import ABC libraries\n",
    "from Hive import Hive\n",
    "from Hive import Utilities\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "dataset = pd.read_csv('data/dataset_bisbul_flavonoid.csv')\n",
    "\n",
    "# Slice dataset into input (X, wavelength features) and output (Y, flavonoid value)\n",
    "num_features = 224\n",
    "X = dataset.iloc[:, :num_features]\n",
    "Y = dataset.iloc[:, 224:225]\n",
    "#Y = dataset.iloc[:,225:226]\n",
    "wavelengths = X.columns.values.tolist()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "n_fold = 5\n",
    "\n",
    "\n",
    "rmse_ori = []\n",
    "fold_num = 5\n",
    "max_components = num_features - 1\n",
    "\n",
    "\n",
    "rmse_train = np.zeros(n_fold)\n",
    "rmse_test  = np.zeros(n_fold)\n",
    "r2_train   = np.zeros(n_fold)\n",
    "r2_test    = np.zeros(n_fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with PLS and Optimization via ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic PLSR Regresion With Few Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====================================================\n",
    "CORE METHOD\n",
    "-------------\n",
    "REGRESSION WITH PLS & PARAMETER OPTIMIZATION VIA ABC\n",
    "=====================================================\n",
    "'''\n",
    "st = time()\n",
    "\n",
    "'''Step 1. Finding PLSR Best Component'''\n",
    "\n",
    "\n",
    "# Data Training and Data Testing Declaration FOR PLSR ALL\n",
    "\n",
    "opt_components = 50\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X, Y)):\n",
    "    X_train, Y_train = X.iloc[train], Y.iloc[train]\n",
    "    X_test, Y_test = X.iloc[test], Y.iloc[test]\n",
    "    \n",
    "    PLSR_ALL = PLSRegression(n_components = opt_components)\n",
    "    PLSR_ALL.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_train_meas_ALL = Y_train\n",
    "    Y_train_pred_ALL = PLSR_ALL.predict(X_train)\n",
    "    Y_test_meas_ALL = Y_test\n",
    "    Y_test_pred_ALL = PLSR_ALL.predict(X_test)\n",
    "\n",
    "    rmse_train[k] = np.sqrt(mse(Y_train_meas_ALL, Y_train_pred_ALL))\n",
    "    r2_train[k] = r2_score(Y_train_meas_ALL, Y_train_pred_ALL)\n",
    "    rmse_test[k] = np.sqrt(mse(Y_test_meas_ALL, Y_test_pred_ALL))\n",
    "    r2_test[k] =  r2_score(Y_test_meas_ALL, Y_test_pred_ALL)\n",
    "\n",
    "    \n",
    "    # Declare input X to be optimized\n",
    "    x_train = X - PLSR_ALL.x_mean_\n",
    "    x_train /= PLSR_ALL.x_std_ \n",
    "    \n",
    "\n",
    "    # Calculate predicted value with Cross-validation\n",
    "    Y_cv = Y_train_pred_ALL\n",
    "    #Y_cv = cross_val_predict(PLSR_ALL, X_train, Y_train, cv = fold_num)\n",
    "\n",
    "    # Get PLSR RMSE\n",
    "    #rmse = np.sqrt(mse(Y_train, Y_cv))\n",
    "    #rmse_ori.append(rmse)\n",
    "\n",
    "# Get limit of coeficient/parameters value B\n",
    "    coef_plsr_ALL = PLSR_ALL.coef_\n",
    "\n",
    "\n",
    "end_time = time() - st\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table = pd.DataFrame([rmse_train, rmse_test, r2_train, r2_test]).transpose()\n",
    "score_table.columns = ['RMSE_train','RMSE_test','R2_train','R2_test']\n",
    "rmse = np.average(rmse_test)\n",
    "rmse_ori.append(rmse)\n",
    "\n",
    "mean_score =  pd.DataFrame(score_table.mean()).transpose()\n",
    "mean_score.index = ['Average']\n",
    "score_table = pd.concat([score_table,mean_score])\n",
    "(score_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and determine the error\n",
    "predictions = PLSR_ALL.predict(X_test)\n",
    "errors = abs(predictions - Y_test)\n",
    "\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / Y_test))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Training Data Only (Without Wavelength Selection)\n",
    "plt.title('PLSR Measured vs. Predicted Value (n = 50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "\n",
    "plt.scatter(Y_train_meas_ALL, Y_train_pred_ALL, label = 'Training Data',color = 'red')\n",
    "#plt.scatter(Y_test_meas_ALL, Y_test_pred_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([100, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.xlim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('PLSR Measured vs. Predicted Value (n=50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "#plt.scatter(Y_train_meas_ALL, Y_train_pred_ALL, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_ALL, Y_test_pred_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('PLSR Measured vs. Predicted Value (n=50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(Y_train_meas_ALL, Y_train_pred_ALL, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_ALL, Y_test_pred_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARTIFICIAL BEE COLONY OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare objective function to be minimized by ABC\n",
    "\n",
    "def R2_abc_ALL(B):\n",
    "    # Declare parameter B to be optimized\n",
    "    B = np.reshape(np.array(B), (num_features, 1))\n",
    "    # Declare input X to be optimized\n",
    "    \n",
    "    length_to_split = int(len(dataset) * 0.8)\n",
    "    X_train = X[:length_to_split]\n",
    "    Y_train = Y[:length_to_split]\n",
    "    x_train = X_train - PLSR_ALL.x_mean_\n",
    "    x_train /= PLSR_ALL.x_std_\n",
    "    kf = KFold(n_splits=5,shuffle=True)\n",
    "    kf.split(X)\n",
    "    return r2_score(Y_train, np.dot(x_train, B) + PLSR_ALL.y_mean_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 4. Optimization of PLSR w/ Selected Wavelengths via ABC'''\n",
    "# Prepare ABC\n",
    "n_bees = 50\n",
    "iter_count = 1\n",
    "lr = 0.0001\n",
    "st = time()\n",
    "\n",
    "\n",
    "\n",
    "# Prepare ABC class for ALL wavelengths\n",
    "lower_lim_ALL = [b - (abs(b)*lr) for b in coef_plsr_ALL] \n",
    "upper_lim_ALL = [b - (abs(b)*lr) for b in coef_plsr_ALL]\n",
    "\n",
    "\n",
    "#abc_model = Hive.BeeHive(lower = lower_lim_ALL,\n",
    "#                         upper = upper_lim_ALL,\n",
    "#                         fun = rmse_abc_ALL,\n",
    "#                         numb_bees = n_bees,\n",
    "#                         max_itrs = iter_count)\n",
    "\n",
    "abc_model = Hive.BeeHive(lower = lower_lim_ALL,\n",
    "                         upper = upper_lim_ALL,\n",
    "                         fun = R2_abc_ALL,\n",
    "                         numb_bees = n_bees,\n",
    "                         max_itrs = iter_count)\n",
    "\n",
    "# Optimize coefficient/parameters value B\n",
    "cost = abc_model.run()\n",
    "rmse_optimized_ALL = abc_model.best\n",
    "coef_optimized_ALL = abc_model.solution\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X, Y)):\n",
    "    X_train, Y_train = X.iloc[train], Y.iloc[train]\n",
    "    X_test, Y_test = X.iloc[test], Y.iloc[test]\n",
    "    \n",
    "    PLSR_ABC_ALL = copy.deepcopy(PLSR_ALL)\n",
    "    PLSR_ABC_ALL.coef_ = coef_optimized_ALL\n",
    "    PLSR_ABC_ALL.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_train_meas_ABC = Y_train\n",
    "    Y_train_pred_ABC = PLSR_ABC_ALL.predict(X_train)\n",
    "    Y_test_meas_ABC = Y_test\n",
    "    Y_test_pred_ABC = PLSR_ABC_ALL.predict(X_test)\n",
    "    \n",
    "    rmse_train[k] = np.sqrt(mse(Y_train_meas_ABC, Y_train_pred_ABC))\n",
    "    r2_train[k] = r2_score(Y_train_meas_ABC, Y_train_pred_ABC)\n",
    "    rmse_test[k] = np.sqrt(mse(Y_test_meas_ABC, Y_test_pred_ABC))\n",
    "    r2_test[k] =  r2_score(Y_test_meas_ABC, Y_test_pred_ABC)\n",
    "end_time = time()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table = pd.DataFrame([rmse_train, rmse_test, r2_train, r2_test]).transpose()\n",
    "score_table.columns = ['RMSE_train','RMSE_test','R2_train','R2_test']\n",
    "rmse = np.average(rmse_test)\n",
    "rmse_ori.append(rmse)\n",
    "\n",
    "mean_score =  pd.DataFrame(score_table.mean()).transpose()\n",
    "mean_score.index = ['Average']\n",
    "score_table = pd.concat([score_table,mean_score])\n",
    "(score_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('PLSR ABC Measured vs. Predicted Value (n = 50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(Y_train_meas_ABC, Y_train_pred_ABC, label = 'Training Data',color = 'red')\n",
    "#plt.scatter(Y_test_meas_ABC, Y_test_pred_ABC, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('PLSR-ABC Measured vs. Predicted Value (n=50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "#plt.scatter(Y_train_meas_ABC, Y_train_pred_ABC, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_ABC, Y_test_pred_ABC, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('PLSR-ABC Measured vs. Predicted Value (n=50)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(Y_train_meas_ABC, Y_train_pred_ABC, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_ABC, Y_test_pred_ABC, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RANDOM FOREST ALL WAVELENGTHS REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/dataset_bisbul_flavonoid.csv')\n",
    "labels = features['Flavonoid']\n",
    "features= features.drop(['Flavonoid'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "RF_ALL = RandomForestRegressor(n_estimators = 1000, random_state = 12121323)\n",
    "for k, (train, test) in enumerate(k_fold.split(features, labels)):\n",
    "    X_train, Y_train = features.iloc[train], labels.iloc[train]\n",
    "    X_test, Y_test = features.iloc[test], labels.iloc[test]\n",
    "    RF_ALL.fit(X_train, Y_train)\n",
    "    pred_train = RF_ALL.predict(X_train)\n",
    "    \n",
    "    Y_train_meas_RF_ALL = Y_train\n",
    "    Y_train_pred_RF_ALL = RF_ALL.predict(X_train)\n",
    "    Y_test_meas_RF_ALL = Y_test\n",
    "    Y_test_pred_RF_ALL = RF_ALL.predict(X_test)\n",
    "    \n",
    "    rmse_train[k] = np.sqrt(mse(Y_train_meas_RF_ALL, Y_train_pred_RF_ALL))\n",
    "    r2_train[k] = r2_score(Y_train_meas_RF_ALL, Y_train_pred_RF_ALL)\n",
    "    rmse_test[k] = np.sqrt(mse(Y_test_meas_RF_ALL, Y_test_pred_RF_ALL))\n",
    "    r2_test[k] =  r2_score(Y_test_meas_RF_ALL, Y_test_pred_RF_ALL)\n",
    "\n",
    "end_time = time()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table = pd.DataFrame([rmse_train, rmse_test, r2_train, r2_test]).transpose()\n",
    "score_table.columns = ['RMSE_train','RMSE_test','R2_train','R2_test']\n",
    "rmse = np.average(rmse_test)\n",
    "rmse_ori.append(rmse)\n",
    "\n",
    "mean_score =  pd.DataFrame(score_table.mean()).transpose()\n",
    "mean_score.index = ['Average']\n",
    "score_table = pd.concat([score_table,mean_score])\n",
    "(score_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and determine the error\n",
    "predictions = RF_ALL.predict(X_test)\n",
    "errors = abs(predictions - Y_test)\n",
    "\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / Y_test))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy RF:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (All Wavelengths)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(Y_train_meas_RF_ALL, Y_train_pred_RF_ALL, label = 'Training Data',color = 'red')\n",
    "#plt.scatter(Y_test_meas_RF_ALL, Y_test_pred_RF_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (All Wavelengths)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "#plt.scatter(Y_train_meas_RF_ALL, Y_train_pred_RF_ALL, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_RF_ALL, Y_test_pred_RF_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (All Wavelengths)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(Y_train_meas_RF_ALL, Y_train_pred_RF_ALL, label = 'Training Data',color = 'red')\n",
    "plt.scatter(Y_test_meas_RF_ALL, Y_test_pred_RF_ALL, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RF SELECTED WAVELENGTH REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(RF_ALL.feature_importances_)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(RF_ALL.feature_importances_)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 50, random_state=1506669923)\n",
    "\n",
    "# Extract the two most important features\n",
    "important_indices = [feature_list.index('731.79'), feature_list.index('726.33'),\n",
    "                    feature_list.index('421.24'), feature_list.index('734.52'),\n",
    "                    feature_list.index('742.72'), feature_list.index('729.06'),\n",
    "                    feature_list.index('737.25'), feature_list.index('413.37'),\n",
    "                    feature_list.index('402.9'), feature_list.index('723.6'),\n",
    "                    feature_list.index('416'), feature_list.index('400.28'),\n",
    "#                     feature_list.index('397.66'), feature_list.index('739.98'),\n",
    "                    feature_list.index('423.86'), feature_list.index('718.15'),\n",
    "                    feature_list.index('972.84'), feature_list.index('405.52'),\n",
    "                    feature_list.index('410.75'), feature_list.index('720.87'),\n",
    "                    feature_list.index('950.38'), feature_list.index('426.49'),\n",
    "                    feature_list.index('431.74'), feature_list.index('452.79'),\n",
    "                    feature_list.index('925.19'), feature_list.index('978.46'),\n",
    "                    feature_list.index('418.62'), feature_list.index('434.37'),\n",
    "                    feature_list.index('455.43'), feature_list.index('712.7'),\n",
    "                    feature_list.index('745.45'), feature_list.index('992.54'),\n",
    "                    feature_list.index('408.13'), feature_list.index('447.52'),\n",
    "                    feature_list.index('715.42'), feature_list.index('781.09'),\n",
    "                    feature_list.index('922.39'), feature_list.index('970.03'),\n",
    "                    feature_list.index('998.17'), feature_list.index('429.12'),\n",
    "                    feature_list.index('439.63'), feature_list.index('444.89'),\n",
    "                    feature_list.index('463.34'), feature_list.index('748.19'),\n",
    "                    feature_list.index('891.71'), feature_list.index('914.02'),\n",
    "                    feature_list.index('919.6'), feature_list.index('947.58'),\n",
    "                    feature_list.index('964.41'), feature_list.index('967.22'),\n",
    "                    feature_list.index('975.65'), feature_list.index('984.09'),\n",
    "                    feature_list.index('437'), feature_list.index('442.26'),\n",
    "                    feature_list.index('450.16'), feature_list.index('458.06'),\n",
    "                    feature_list.index('460.7'), feature_list.index('468.62'),\n",
    "                    feature_list.index('471.26'), feature_list.index('481.83'),\n",
    "                    feature_list.index('484.47'), feature_list.index('487.12'),\n",
    "                    feature_list.index('526.93'), feature_list.index('529.59'),\n",
    "                    feature_list.index('534.91'), feature_list.index('537.57'),\n",
    "                    feature_list.index('540.24'), feature_list.index('542.91'),\n",
    "                    feature_list.index('545.57'), feature_list.index('548.24'),\n",
    "                    feature_list.index('550.91'), feature_list.index('553.58'),\n",
    "                    feature_list.index('556.25'), feature_list.index('558.92'),\n",
    "                    feature_list.index('561.59'), feature_list.index('564.26'),\n",
    "                    feature_list.index('661.1'), feature_list.index('663.81'),\n",
    "                    feature_list.index('674.65'), feature_list.index('685.5'),\n",
    "                    feature_list.index('693.65'), feature_list.index('699.09'),\n",
    "                    feature_list.index('701.81'), feature_list.index('704.53'),\n",
    "                    feature_list.index('707.25'), feature_list.index('709.97'),\n",
    "                    feature_list.index('750.93'), feature_list.index('753.66'),\n",
    "                    feature_list.index('759.14'), feature_list.index('764.62'),\n",
    "                    feature_list.index('772.85'), feature_list.index('775.6'),\n",
    "                    feature_list.index('778.34'), feature_list.index('786.58'),\n",
    "                    feature_list.index('800.34'), feature_list.index('805.85'),\n",
    "                    feature_list.index('808.61'), feature_list.index('875.03'),\n",
    "                    feature_list.index('888.93'), feature_list.index('897.28'),\n",
    "                    feature_list.index('902.86'), feature_list.index('916.81'),\n",
    "                    feature_list.index('930.78'), feature_list.index('939.18'),\n",
    "                    feature_list.index('955.99'), feature_list.index('958.8'),\n",
    "                    feature_list.index('961.6'), feature_list.index('981.27'),\n",
    "                    feature_list.index('986.9'), feature_list.index('989.72'),\n",
    "                    feature_list.index('995.35'), feature_list.index('1000.99'),\n",
    "                    feature_list.index('1003.81')]\n",
    "\n",
    "train_features_nparr = np.array(X_train)\n",
    "test_features_nparr = np.array(X_test)\n",
    "\n",
    "train_important = train_features_nparr[:, important_indices]\n",
    "test_important = test_features_nparr[:, important_indices]\n",
    "\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "for k, (train, test) in enumerate(k_fold.split(features, labels)):\n",
    "    X_train, y_train = features.iloc[train], labels.iloc[train]\n",
    "    X_test, y_test = features.iloc[test], labels.iloc[test]\n",
    "#    print('Train:', train, 'Test:', test)\n",
    "    \n",
    "    train_features_nparr = np.array(X_train)\n",
    "    test_features_nparr = np.array(X_test)\n",
    "\n",
    "    train_important = train_features_nparr[:, important_indices]\n",
    "    test_important = test_features_nparr[:, important_indices]\n",
    "    \n",
    "    rf_most_important.fit(train_important, y_train)\n",
    "    \n",
    "    \n",
    "    train_features_nparr = np.array(X_train)\n",
    "    test_features_nparr = np.array(X_test)\n",
    "\n",
    "    train_important = train_features_nparr[:, important_indices]\n",
    "    test_important = test_features_nparr[:, important_indices]\n",
    "    \n",
    "    rf_most_important.fit(train_important, y_train)\n",
    "    pred_train = rf_most_important.predict(train_important)\n",
    "    rmse_train[k] = np.sqrt(mse(y_train, pred_train))\n",
    "    r2_train[k] = rf_most_important.score(train_important, y_train)\n",
    "    pred_test = rf_most_important.predict(test_important)\n",
    "    rmse_test[k] = np.sqrt(mse(y_test, pred_test))\n",
    "    r2_test[k] = rf_most_important.score(test_important, y_test)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "score_table = pd.DataFrame([rmse_train, rmse_test, r2_train, r2_test]).transpose()\n",
    "score_table.columns = ['RMSE_train','RMSE_test','R2_train','R2_test']\n",
    "\n",
    "mean_score =  pd.DataFrame(score_table.mean()).transpose()\n",
    "mean_score.index = ['Average']\n",
    "score_table = pd.concat([score_table,mean_score])\n",
    "#score_table.to_csv(OUTPUT_PATH+'CrossVal_Using_Feature_selection_2.csv')\n",
    "(score_table)\n",
    "end_time = time()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (Feature Selected)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(y_train, pred_train, label = 'Training Data',color = 'red')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (Feature Selected)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "#plt.scatter(y_train, pred_train, label = 'Training Data',color = 'red')\n",
    "plt.scatter(y_test, pred_test, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot Testing Data Only (ALL wavelengths)\n",
    "plt.title('RF Measured vs. Predicted Value (Feature Selected)')\n",
    "plt.xlabel('Measured Value[Flavonoid (mg/ml)]')\n",
    "plt.ylabel('Predicted Value[Flavonoid (mg/ml)]')\n",
    "gradien_x = list(range(0,1500))\n",
    "gradien_y = list(range(0,1500))\n",
    "plt.scatter(y_train, pred_train, label = 'Training Data',color = 'red')\n",
    "plt.scatter(y_test, pred_test, label = 'Test Data',color = 'blue')\n",
    "plt.plot(gradien_x,gradien_y,color='black',dashes=[6, 2])\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.xlim([0, 500])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.ylim([0, 500])\n",
    "plt.gcf().set_size_inches(12.5, 10)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
